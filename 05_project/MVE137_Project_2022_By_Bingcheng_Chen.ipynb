{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42d4e64",
   "metadata": {},
   "source": [
    "**Project Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325c54a",
   "metadata": {},
   "source": [
    "**Formalities**\n",
    "\n",
    "This is the project for the course Probability and Statistical Learning Using Python, 2022. Here, you are asked to carry out the analysis using the tools, techniques, and skills acquired in the course and hand in a .pynb file with the solutions.\n",
    "\n",
    "The **deadline  is Friday, October\n",
    "28, 2022.** You should upload the solution file to 'Project Assignment' in Canvas via 'Home-->Project Assignment'.\n",
    "Note that this is an individual exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab58442",
   "metadata": {},
   "source": [
    "**Part I**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a735f",
   "metadata": {},
   "source": [
    "In this exercise we will estimate the test error of logistic regression model using the below described validation set approach. You will neeed to import the *Default.csv* file provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679f0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b68f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "df = pd.read_csv(\"Default.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6928055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>919.588531</td>\n",
       "      <td>7491.558572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>825.513331</td>\n",
       "      <td>24905.226580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>808.667504</td>\n",
       "      <td>17600.451340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1161.057854</td>\n",
       "      <td>37468.529290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29275.268290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default student      balance        income\n",
       "1       No      No   729.526495  44361.625070\n",
       "2       No     Yes   817.180407  12106.134700\n",
       "3       No      No  1073.549164  31767.138950\n",
       "4       No      No   529.250605  35704.493940\n",
       "5       No      No   785.655883  38463.495880\n",
       "6       No     Yes   919.588531   7491.558572\n",
       "7       No      No   825.513331  24905.226580\n",
       "8       No     Yes   808.667504  17600.451340\n",
       "9       No      No  1161.057854  37468.529290\n",
       "10      No      No     0.000000  29275.268290"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83130eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default    0\n",
       "student    0\n",
       "balance    0\n",
       "income     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there is any missing values in dataset due to data corruption\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e4c6d",
   "metadata": {},
   "source": [
    "(a) Fit a logistic regression model that uses $income$ and $balance$ to\n",
    "predict $default$ and print out the summary. **(3 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786cea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                  0.4594\n",
      "Time:                        15:51:46   Log-Likelihood:                -789.48\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -11.5244      0.433    -26.635      0.000     -12.372     -10.676\n",
      "balance       14.9892      0.604     24.835      0.000      13.806      16.172\n",
      "income         1.5145      0.363      4.174      0.000       0.803       2.226\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# map 'Yes' and 'No' to '1' and '0'\n",
    "df['default'] = df['default'].map({'Yes': 1, 'No': 0})\n",
    "df['student'] = df['student'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# scale the feature, Use MinMaxScaler method\n",
    "X = df[['balance','income']]\n",
    "y = df['default']\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaler = scaler.fit_transform(X)\n",
    "\n",
    "# generate new dataframe df_scaled which contains column 'default' and scaled 'balance'&'income', set index start from 1 as df \n",
    "df_scaled = pd.DataFrame(X_scaler, columns=['balance','income'])\n",
    "df_scaled.index = np.arange(1,len(df_scaled)+1)\n",
    "df_scaled['default'] = df['default']\n",
    "\n",
    "# create the model and fit it\n",
    "logit_model = smf.logit(formula='default~balance+income',data=df_scaled)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302291b",
   "metadata": {},
   "source": [
    "(b) You are supposed to estimate the test error of this model using the validation set approach described below. In order to do this, you must perform the following steps: **(4 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31129a5",
   "metadata": {},
   "source": [
    "i. Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff91e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_scaler, y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41deb6",
   "metadata": {},
   "source": [
    "ii. Fit a multiple logistic regression model using only the training\n",
    "observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52306566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.94692825]\n",
      "[[14.31448795  1.081739  ]]\n"
     ]
    }
   ],
   "source": [
    "# fit the logistic regression model using training dataset\n",
    "model = LogisticRegression(penalty=\"none\",max_iter=1000,solver = \"newton-cg\")\n",
    "# model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e13126",
   "metadata": {},
   "source": [
    "iii. Obtain a prediction of default status for each individual in\n",
    "the validation set (test set) by computing the posterior probability of\n",
    "$default$ for that individual, and classifying the individual to\n",
    "the $default$ category if the posterior probability is greater\n",
    "than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e4618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bfa3b",
   "metadata": {},
   "source": [
    "iv. Compute the validation set error, which is the fraction of\n",
    "the observations in the validation set (test set) that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a636670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observations in the validation set (test set) that are misclassified is 0.025000000000000022\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_validation, predictions, normalize=True)\n",
    "print(f'The observations in the validation set (test set) that are misclassified is {1.0-score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f375ea",
   "metadata": {},
   "source": [
    "(c) Now consider a logistic regression model that predicts the probability of default using $income$, $balance$, a dummy variable for $student$ and print the summary. Estimate the test error for this model using the validation\n",
    "set approach. Comment on the results. Does the inclusion of a dummy variable for student lead to a reduction in the test error? **(3 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e54900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078577\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                  0.4619\n",
      "Time:                        15:51:46   Log-Likelihood:                -785.77\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.257e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -10.8667      0.488    -22.263      0.000     -11.823      -9.910\n",
      "student       -0.6468      0.236     -2.738      0.006      -1.110      -0.184\n",
      "balance       15.2265      0.616     24.737      0.000      14.020      16.433\n",
      "income         0.2208      0.597      0.370      0.712      -0.949       1.391\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "After adding \"student\" as a dummy variable, the observations in the validation set (test set) that are misclassified is 0.025666666666666615\n"
     ]
    }
   ],
   "source": [
    "# generate new dataframe df_scaled_2, create the model and fit it \n",
    "df_scaled['student'] = df['student']\n",
    "\n",
    "logit_model = smf.logit(formula='default ~ student + balance + income',data=df_scaled)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "# Split the sample set into a new training set and a validation set.\n",
    "X_train2, X_validation2, y_train2, y_validation2 = train_test_split(df_scaled[['student','balance','income']], y, test_size=0.3, random_state=5)\n",
    "model2 = LogisticRegression(penalty=\"none\",max_iter=1000,solver = \"newton-cg\")\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "# Estimate the test error for this model using the validation dataset\n",
    "predictions_2 = model2.predict(X_validation2)\n",
    "score_2 = accuracy_score(y_validation2, predictions_2, normalize=True)\n",
    "print('')\n",
    "print(f'After adding \"student\" as a dummy variable, the observations in the validation set (test set) that are misclassified is {1.0-score_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f0267",
   "metadata": {},
   "source": [
    "$\\textbf{Answer}$:  \n",
    "The test error before is about 0.025, after adding 'student' as a dummy variable, the fraction of test error is 0.025667, so the inclusion of a dummy variable for student doesn't lead to a reduction in the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f6b09",
   "metadata": {},
   "source": [
    "**Part II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb2b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import seaborn\n",
    "from scipy.spatial.distance import euclidean\n",
    "import warnings\n",
    "\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f0854",
   "metadata": {},
   "source": [
    "In this exercise, you will demonstrate your understanding of the KNN classification algorithm and test it on a breast cancer dataset. The algorithm should be implemented in pure python, without using the sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ce805",
   "metadata": {},
   "source": [
    "**KNN algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048b3fc",
   "metadata": {},
   "source": [
    "(a)  Implement a function of your own to perform KNN classification **without using the default available libraries such as KNeighborsClassifier() in sklearn**. You will need to consider the Euclidean distances between the features and data to be predicted (test data) when selecting the k-nearest neighbors. The function should take 3 inputs as 1) data set to train the model 2) data to test 3) number of neighbours (k). If *k* is set to a value less than or equal to the total classification groups, the function should give a warning, and  warn() function defined in the 'warning' module will be useful for that.\n",
    "\n",
    "The function should output *classification_result*, where *classification_result* is the result of your classifier. Further, you should provide a suitable measure of the confidence on the classification. Justify your choice. \n",
    "\n",
    "Please note that only a few basic libraries/modules are imported and thus you are expected to import the needed others. \n",
    "\n",
    "\n",
    "\n",
    "**Hint:** You may fill and complete the function given below.                **(5 pts)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d468242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_algorithm(traindata, testdata, k_neighbours=5):\n",
    "    \n",
    "    classification_result = np.zeros(shape=(1,testdata.shape[0]))\n",
    "    confidence_array = np.zeros(shape=(1,testdata.shape[0]))\n",
    "\n",
    "    # set a warning message when k is less than or equal to the total classification groups\n",
    "    if k_neighbours <= traindata.drop(testdata.columns.values, axis=1).nunique().values:\n",
    "        warnings.warn('k is set to a value less than or equal to the total classification groups')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # convert pandas.dataframe to np.array, to speed up the running time when calculating Euclidean distances\n",
    "    traindata_X_array = traindata[testdata.columns].to_numpy()\n",
    "    traindata_y_array = traindata.drop(testdata.columns, axis=1).to_numpy()\n",
    "    test_data_array = testdata.to_numpy()\n",
    "\n",
    "    # Calculate Euclidean distances\n",
    "    for i in range(testdata.shape[0]):\n",
    "        near_points = None\n",
    "        feature_distance_list = []\n",
    "\n",
    "        x_columns = testdata.columns\n",
    "        for j in range(traindata.shape[0]):\n",
    "            \n",
    "            # for each 'point' in testing dataset, calculate distance with all 'points' in training dataset\n",
    "            euclidean_distance = np.sqrt(np.sum((test_data_array[i]-traindata_X_array[j])**2))\n",
    "\n",
    "            # for each 'point' in testing, generate a list which contains all value of y and euclidean distance\n",
    "            feature_distance_list.append([traindata_y_array[j][0], euclidean_distance])\n",
    "\n",
    "        # sorted the list by distance generated in the last step\n",
    "        sorted_list = sorted(feature_distance_list,key=lambda x:x[1])\n",
    "        df_sorted_list = pd.DataFrame(sorted_list, columns=['dependent_variable','distance'])\n",
    "\n",
    "\n",
    "        # take the first k_neighbours rows, which is exactly the k_nearest neighbours\n",
    "        df_neighbours = df_sorted_list.head(k_neighbours)\n",
    "\n",
    "        # k_neighbours vote for the final result, minority obeys majority\n",
    "        classes = df_neighbours['dependent_variable'].value_counts()\n",
    "        proportions = classes / classes.sum()\n",
    "        classification_result[0][i] = proportions.index[0]\n",
    "\n",
    "        # confidence for each 'point' in testing dataset is the proportion of the classification_result (the rate of the majority)\n",
    "        confidence_array[0][i] = proportions.iloc[0]\n",
    "\n",
    "    # confidence = np.mean(confidence_array)\n",
    "       \n",
    "    return classification_result, confidence_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b1202",
   "metadata": {},
   "source": [
    "#### Now let's test the implemented KNN algorithm on the given breast cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd0f63",
   "metadata": {},
   "source": [
    "This dataset contains records of breast cancer patients. Here we will use the features (columns) to predict the correct cancer class (last column) for the patients in the dataset as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27af2716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0  1000025                5               1                1              1   \n",
       "1  1002945                5               4                4              5   \n",
       "2  1015425                3               1                1              1   \n",
       "3  1016277                6               8                8              1   \n",
       "4  1017023                4               1                1              3   \n",
       "5  1017122                8              10               10              8   \n",
       "6  1018099                1               1                1              1   \n",
       "7  1018561                2               1                2              1   \n",
       "8  1033078                2               1                1              1   \n",
       "9  1033078                4               2                1              1   \n",
       "\n",
       "   single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                       2           1            3              1        1   \n",
       "1                       7          10            3              2        1   \n",
       "2                       2           2            3              1        1   \n",
       "3                       3           4            3              7        1   \n",
       "4                       2           1            3              1        1   \n",
       "5                       7          10            9              7        1   \n",
       "6                       2          10            3              1        1   \n",
       "7                       2           1            3              1        1   \n",
       "8                       2           1            1              1        5   \n",
       "9                       2           1            2              1        1   \n",
       "\n",
       "   class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  \n",
       "5      4  \n",
       "6      2  \n",
       "7      2  \n",
       "8      2  \n",
       "9      2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['id', 'clump_thickness', 'unif_cell_size', 'unif_cell_shape', 'marg_adhesion',\n",
    "           'single_epith_cell_size', 'bare_nuclei', 'bland_chrom', 'norm_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data', header=None, names=columns)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb999d6b",
   "metadata": {},
   "source": [
    "#### Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be7ad9",
   "metadata": {},
   "source": [
    "(b) Check how many different cancer classes are available, and plot a pie chart to see the distribution of classes. Then, find and replace all the missing values with the mode of the particular column(s). Note that the missing values are marked with '?' in the dataset. **(1 pt)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4883d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 different cancer classes, which are class 2 and class 4.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "clump_thickness            0\n",
       "unif_cell_size             0\n",
       "unif_cell_shape            0\n",
       "marg_adhesion              0\n",
       "single_epith_cell_size     0\n",
       "bare_nuclei               16\n",
       "bland_chrom                0\n",
       "norm_nucleoli              0\n",
       "mitoses                    0\n",
       "class                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect how many different cancer classes \n",
    "uniqueValues = df['class'].unique()\n",
    "print(f'There are {len(uniqueValues)} different cancer classes, which are class {uniqueValues[0]} and class {uniqueValues[1]}.')\n",
    "\n",
    "# plot pie chart\n",
    "fig , ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "classes = df['class'].value_counts()\n",
    "proportions = classes / classes.sum()\n",
    "labels = ['class{}~{:.3}%'.format(i,v*100) for i,v in proportions.items()]\n",
    "\n",
    "classes.plot.pie(ax=ax, colors=['b','r'], labels=labels)\n",
    "ax.set_ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# find the missing value, first repalce it to NaN\n",
    "df = df.replace(['?'],np.NaN)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae28e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0\n",
       "clump_thickness           0\n",
       "unif_cell_size            0\n",
       "unif_cell_shape           0\n",
       "marg_adhesion             0\n",
       "single_epith_cell_size    0\n",
       "bare_nuclei               0\n",
       "bland_chrom               0\n",
       "norm_nucleoli             0\n",
       "mitoses                   0\n",
       "class                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the missing value with the mode value of that column\n",
    "df = df.apply(pd.to_numeric)\n",
    "mode = df['bare_nuclei'].mode()\n",
    "df['bare_nuclei'].fillna(mode[0], inplace =True)\n",
    "\n",
    "# check the missing value again, this time the number of missing value should be 0\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80206cd",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a7b6c",
   "metadata": {},
   "source": [
    "(c) Drop the obiviously unwanted column(s). **(1 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67debe30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0                5               1                1              1   \n",
       "1                5               4                4              5   \n",
       "2                3               1                1              1   \n",
       "3                6               8                8              1   \n",
       "4                4               1                1              3   \n",
       "\n",
       "   single_epith_cell_size  bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                       2          1.0            3              1        1   \n",
       "1                       7         10.0            3              2        1   \n",
       "2                       2          2.0            3              1        1   \n",
       "3                       3          4.0            3              7        1   \n",
       "4                       2          1.0            3              1        1   \n",
       "\n",
       "   class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unwanted column - 'id'\n",
    "df = df.drop(\"id\",axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f60fc",
   "metadata": {},
   "source": [
    "#### Split the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7067dc",
   "metadata": {},
   "source": [
    "(d) In here, you will split the data into training and test sets, **without using sklearn library.** Please use 20% of the dataset as test set and the rest for train set. Shuffle the data prior to splitting in order to prevent any bias during the training and to avoid the model from learning the order of the training. **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e09a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X, y, test_size, random_state=None):\n",
    "\n",
    "    # add y as a column to X, use df.sample() to shuffle the whole dataset\n",
    "    X = pd.DataFrame(X)\n",
    "    X[y.columns.values.tolist()[0]] = y\n",
    "    shuffled_df = X.sample(frac=1,random_state=random_state)\n",
    "\n",
    "    # calculate the number of training dataset and testing dataset\n",
    "    total_number = X.shape[0]\n",
    "    number_of_testdata = int(np.ceil(total_number*test_size))\n",
    "    number_of_traindata = total_number - number_of_testdata\n",
    "\n",
    "    # get the training dataset and testing dataset\n",
    "    train_set = shuffled_df[:number_of_traindata]\n",
    "    test_set = shuffled_df[number_of_traindata:]\n",
    "\n",
    "    # split the testing dataset to X_test and y_test\n",
    "    # X_train = train_set.drop(y.columns.values, axis=1)\n",
    "    # y_train = train_set[y.columns.values]\n",
    "    X_test = test_set.drop(y.columns.values, axis=1)\n",
    "    y_test = test_set[y.columns.values]\n",
    "\n",
    "    # return X_train, X_test, y_train, y_test\n",
    "    return train_set, X_test, y_test\n",
    "\n",
    "# define dataset\n",
    "X = df.drop(['class'],axis=1)\n",
    "y = df[['class']]\n",
    "\n",
    "# scale the feature, Use StandardScaler method\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)\n",
    "\n",
    "# Split the Training and Test dataset,set test_size = 0.2\n",
    "train_dataset, X_test, y_test = my_train_test_split(X_scaler, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eda4a2",
   "metadata": {},
   "source": [
    "#### Predict the class for test data and calculate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173dff6",
   "metadata": {},
   "source": [
    "(e) Now train the KNN classifier you developed in (a) using the training set, and test it on the test set with *k_neighbours=5*. **(4 pts)**\n",
    "\n",
    "Print the confidence for the incorrect predictions the classifier has made.\n",
    "\n",
    "Find the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad73b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When test_size is 0.2, the accuracy of the predictions is: 0.9714\n",
      "When test_size is 0.2, the confidence for the incorrect predictions the classifier has made is : [0.6, 0.6, 0.8, 0.6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create KNN model and output the prediction and confidence\n",
    "result,confidence = knn_algorithm(train_dataset, X_test, k_neighbours=5)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "y_true = y_test.transpose().to_numpy().astype(int)\n",
    "accuracy = accuracy_score(y_true[0], result.astype(int)[0])\n",
    "print('When test_size is 0.2, the accuracy of the predictions is: {:.4f}'.format(accuracy))\n",
    "\n",
    "# define function to output the confidence for the incorrect predictions\n",
    "def incorrect_prediction_confidence(y_true,result,confidence):\n",
    "\n",
    "    incorrect_pred_confidence = []\n",
    "    for i in range(len(y_true[0])):\n",
    "        if y_true[0][i] == result.astype(int)[0][i]:\n",
    "            pass\n",
    "        else:\n",
    "            incorrect_pred_confidence.append(confidence[0][i])\n",
    "    return incorrect_pred_confidence\n",
    "\n",
    "# output the confidence for the incorrect predictions\n",
    "incorrect_pred_confidence = incorrect_prediction_confidence(y_true,result,confidence)\n",
    "print('When test_size is 0.2, the confidence for the incorrect predictions the classifier has made is :', incorrect_pred_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f358925",
   "metadata": {},
   "source": [
    "**Effect of reduction in training data size on confidence of predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5137829",
   "metadata": {},
   "source": [
    "(f) Now increase the test set size to 40% of the dataset while keeping the same *k_neighbours* and print the confidence and accuracy of the predictions similar to the previous question. Explain the results in comparison with (e) **(2 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9f89bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When test_size is 0.4, the accuracy of the predictions is: 0.9643\n",
      "When test_size is 0.4, the confidence for the incorrect predictions the classifier has made is : [0.6, 0.8, 0.6, 0.6, 1.0, 1.0, 0.6, 0.6, 0.8, 0.6]\n"
     ]
    }
   ],
   "source": [
    "# split the training dataset and testing dataset, set test_size=0.4\n",
    "train_dataset2, X_test2, y_test2 = my_train_test_split(X_scaler, y, test_size=0.4, random_state=5)\n",
    "\n",
    "# create KNN model and output the prediction and confidence\n",
    "result2,confidence2 = knn_algorithm(train_dataset2, X_test2, k_neighbours=5)\n",
    "\n",
    "# calculate the accuracy of the model\n",
    "y_true2 = y_test2.transpose().to_numpy().astype(int)\n",
    "accuracy = accuracy_score(y_true2[0], result2.astype(int)[0])\n",
    "print('When test_size is 0.4, the accuracy of the predictions is: {:.4f}'.format(accuracy))\n",
    "\n",
    "# output the confidence for the incorrect predictions\n",
    "incorrect_pred_confidence = incorrect_prediction_confidence(y_true2,result2,confidence2)\n",
    "print('When test_size is 0.4, the confidence for the incorrect predictions the classifier has made is :', incorrect_pred_confidence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4e53b",
   "metadata": {},
   "source": [
    "$\\textbf{Answer}$:\n",
    " \n",
    "When increase test set size to 40%,  the accuracy of model predictions decreases from 97.14% to 96.43% and the mean of confidence for the incorrect predictions increases.  \n",
    "This is because the total size of dataset for trainng and testing is fixed, when we increase the test set size from 20% to 40%, which means the model get less datasets for training, so the accuracy decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a84cc8",
   "metadata": {},
   "source": [
    "#### Alternative classification methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c8ec6",
   "metadata": {},
   "source": [
    "(g) Propose alternative classification approaches for this problem and discuss the advantages and disadvantages with respect to KNNs (you don't need to implement them). **(2 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6232e80",
   "metadata": {},
   "source": [
    "$\\textbf{1. Logistic Regression}$ model can be used for this problem  \n",
    " - $\\textbf{advantages}$:\n",
    "\n",
    "    - Logistic Regression model can handle a large number of feature, however, the KNNs doesn't work well with a high number of dimensions.\n",
    "    - Logistic Regression is comparatively faster than KNNs.\n",
    "\n",
    "- $\\textbf{disadvantages}$:\n",
    "\n",
    "    - Logistic regression assumes that the dependent variable only takes on two possible outcomes, but KNNs can handle more dependent variable values.\n",
    "    - Logistic regression assumes that the observations in the dataset are independent of each other which is usually not true in reality, but KNNs doesn't have that assumption.\n",
    "\n",
    "\n",
    "$\\textbf{2. Decision Tree Classification}$ can also be used for this problem \n",
    " \n",
    " - $\\textbf{advantages}$:\n",
    "    - There is less requirement of data preprocessing compared to KNNs, KNNs are  more sensitive to noisy and missing data, and in KNNs the feature should be scaled properly.\n",
    "\n",
    " - $\\textbf{disadvantages}$:\n",
    "    - Decision Tree Classification could be more instable than KNNs because of a small change in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 21 2022, 22:22:30) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
